{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60c34f5f",
   "metadata": {
    "id": "60c34f5f"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d9efc6",
   "metadata": {
    "id": "93d9efc6"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9687e29b",
   "metadata": {
    "id": "9687e29b"
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d0160e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "07d0160e",
    "outputId": "3ed77dc7-4f6f-4ef6-e2a8-147ab75796c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>input Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                         input Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\kondu\\Desktop\\255-Team-13\\Data\\spamSMS.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b7439",
   "metadata": {
    "id": "f60b7439"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "962e3a2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "962e3a2d",
    "outputId": "e0d48456-f2e4-4dcb-e281-e667aeee61bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5550, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[(data[\"No_of_Char\"]<350)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cc12d45",
   "metadata": {
    "id": "5cc12d45"
   },
   "outputs": [],
   "source": [
    "#function to clean input text\n",
    "def clean_data(inputText):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', inputText) #Replacing all non-alphabetic characters with a space\n",
    "    text = text.lower() #converting input to lowercase\n",
    "    text = text.split()\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6025bb5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6025bb5",
    "outputId": "690a1f55-4f2f-4133-f9e3-a45ed7a3a6cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kondu\\AppData\\Local\\Temp\\ipykernel_36364\\1539644974.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"cleaned_text\"] = data[\"input Text\"].apply(clean_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    go until jurong point crazy available only in ...\n",
       "1                              ok lar joking wif u oni\n",
       "2    free entry in a wkly comp to win fa cup final ...\n",
       "3          u dun say so early hor u c already then say\n",
       "4    nah i don t think he goes to usf he lives arou...\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning input text\n",
    "data[\"cleaned_text\"] = data[\"input Text\"].apply(clean_data)\n",
    "data[\"cleaned_text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c55cbf",
   "metadata": {
    "id": "92c55cbf"
   },
   "source": [
    "**Here, I replaced all non-alphabetic characters with a space and converted the text to lower case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55ef2c2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55ef2c2c",
    "outputId": "e1d63cec-e9cc-466e-c32a-ae0d55666cb6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kondu\\AppData\\Local\\Temp\\ipykernel_36364\\2764974977.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"Tokenized_Text\"]=data.apply(lambda row: nltk.word_tokenize(row[\"cleaned_text\"]), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [go, until, jurong, point, crazy, available, o...\n",
       "1                       [ok, lar, joking, wif, u, oni]\n",
       "2    [free, entry, in, a, wkly, comp, to, win, fa, ...\n",
       "3    [u, dun, say, so, early, hor, u, c, already, t...\n",
       "4    [nah, i, don, t, think, he, goes, to, usf, he,...\n",
       "Name: Tokenized_Text, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization\n",
    "data[\"Tokenized_Text\"]=data.apply(lambda row: nltk.word_tokenize(row[\"cleaned_text\"]), axis=1)\n",
    "data[\"Tokenized_Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ba69c",
   "metadata": {
    "id": "9b7ba69c"
   },
   "source": [
    "**Here, I split the sentence into words(tokens) to remove stopwords in the next step.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "917aa8a9",
   "metadata": {
    "id": "917aa8a9"
   },
   "outputs": [],
   "source": [
    "# function to Remove stopwords\n",
    "def removing_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_text = [word for word in text if word not in stop_words]\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba881c14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba881c14",
    "outputId": "f7c9a596-d7c5-460a-9f0e-8825ee3556a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kondu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a18f154a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a18f154a",
    "outputId": "d8487fe6-aaeb-425c-eff5-f490b3486f48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kondu\\AppData\\Local\\Temp\\ipykernel_36364\\2569495026.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"No_stopword_Text\"] = data[\"Tokenized_Text\"].apply(removing_stopwords)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [go, jurong, point, crazy, available, bugis, n...\n",
       "1                       [ok, lar, joking, wif, u, oni]\n",
       "2    [free, entry, wkly, comp, win, fa, cup, final,...\n",
       "3        [u, dun, say, early, hor, u, c, already, say]\n",
       "4       [nah, think, goes, usf, lives, around, though]\n",
       "Name: No_stopword_Text, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"No_stopword_Text\"] = data[\"Tokenized_Text\"].apply(removing_stopwords)\n",
    "data[\"No_stopword_Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c63dc",
   "metadata": {
    "id": "590c63dc"
   },
   "source": [
    "**Stopwords give meaning to the sentence structure but do not contribute in NLP. so, I removed stopwords from the input text.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88856884",
   "metadata": {
    "id": "88856884"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatization(text):\n",
    "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in text]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86ce9fd7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86ce9fd7",
    "outputId": "7cd1046c-c62b-4c65-f32b-2a4f0c328d3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kondu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f13c7932",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f13c7932",
    "outputId": "54a864e2-6e1c-49c2-b248-310aadc17e72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kondu\\AppData\\Local\\Temp\\ipykernel_36364\\2582914760.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"Lemmatized_Text\"] = data[\"No_stopword_Text\"].apply(lemmatization)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [go, jurong, point, crazy, available, bugis, n...\n",
       "1                         [ok, lar, joke, wif, u, oni]\n",
       "2    [free, entry, wkly, comp, win, fa, cup, final,...\n",
       "3        [u, dun, say, early, hor, u, c, already, say]\n",
       "4          [nah, think, go, usf, live, around, though]\n",
       "Name: Lemmatized_Text, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Lemmatized_Text\"] = data[\"No_stopword_Text\"].apply(lemmatization)\n",
    "data[\"Lemmatized_Text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b7ddaa4",
   "metadata": {
    "id": "2b7ddaa4"
   },
   "outputs": [],
   "source": [
    "corpus= []\n",
    "for i in data[\"Lemmatized_Text\"]:\n",
    "    msg = ' '.join([row for row in i])\n",
    "    corpus.append(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d4262f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d4262f1",
    "outputId": "b41a0fdb-dc5e-4d47-f451-44a0ef5e12c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point crazy available bugis n great world la e buffet cine get amore wat',\n",
       " 'ok lar joke wif u oni',\n",
       " 'free entry wkly comp win fa cup final tkts st may text fa receive entry question std txt rate c apply',\n",
       " 'u dun say early hor u c already say',\n",
       " 'nah think go usf live around though']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64dc92a4",
   "metadata": {
    "id": "64dc92a4"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2229657",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2229657",
    "outputId": "aca8429e-4444-42b2-dd16-053241dd2805"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(corpus).toarray()\n",
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7655b4d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7655b4d4",
    "outputId": "2aee88e1-3608-47ef-c28b-6b9e737b3736"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kondu\\AppData\\Local\\Temp\\ipykernel_36364\\1711342699.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"Class\"] = label_encoder.fit_transform(data[\"Class\"])\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data[\"Class\"] = label_encoder.fit_transform(data[\"Class\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Updated_SMS_Spam_Classifier_Hashmitha_Katta_Final-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
